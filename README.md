# Forex Tester AI FAQ

## Короткий опис
На початку розробки переді мною стояло головне завдання: "Як вмістити в контекст моделі GPT-3.5 інформацію, що в 90 разів перевищує максимальний розмір контексту потрібної моделі?"

Мій перший крок був з'ясувати, які саме дані мені потрібно векторизувати. Виявилося, що в основному мені потрібно векторизувати список питань, а відповіді та іншу необхідну інформацію я можу отримати безпосередньо з JSON файлу.

Векторизацію я виконав за допомогою моделі `text-embedding-ada-002` від OpenAI. Після цього, я зберіг пару `Question ID` - `Embedding` в файл `FAQ.pkl`.

Якщо ви бажаєте, ви також можете виконати команду `python 01_create_embedings.py`, щоб векторизувати дані з файлу `FAQ.json`.

Після успішної векторизації я вирішив створити власний `QuestionRetriever`. Ви можете ознайомитися з ним в `core/retriever.py`.

Процес отримання відповіді на питання користувача включає такі кроки:
1. При ініціалізації сервера в setting.py завантажується assistant, який відповідає за пошук по векторах, і роботу з open ai api.
2. Код векторизує питання користувача.
3. Код виконує пошук найближчого вектора до вектора питання користувача (за методом косинусної подібності).
4. Потім код бере 7 найкращих співпадінь.
5. У контекст блоку FAQ витягується `Answer_plain_text`, `Notes`, `Question_original`, `Question_short`.
6. За допомогою langchain контекст семи блоків передається в модель GPT-3.5.
7. Після того як ми отримали відповідь, одразу передаємо її користувачу.

## Початок роботи

### Попередня ініціалізація
1. `python -m poetry install`
2. `python -m poetry shell`
3. `python manage.py migrate`

### Підготовка інформації
1. Вставте, або оновіть файл `FAQ.json` в директорію `static`
2. Підготовте файл `.env`, приклад ви можете знайти в `.envexample`
   1. `OPENAI_API_KEY` - ключ для OpenAI API
3. Векторизуйте дані `python 01_create_embedings.py`, або вставсте існуючий файл `FAQ.pkl` в директорію `static`

### Запуск сервера
1. `python manage.py runserver`